Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.

Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.

In this project we evaluated, cleaned, and combined data from alternative sources to create an rpart model and an lm model to predict default risk. With this model HomeCredit can expand its business to those without credit histories, while still avoiding risk.

In preparation for the modelling we examined the data and removed variables that could be discriminatory such as age and gender. Then we cleaned the data by removing null values, removing variables with near-zero variance, removing variables that were highly correlated, and factoring data types. Finally we joined the data sources into one data frame and separated it into testing and training data frames based on a 70% split.

In-sample performance of the regression model is 91.8% and the out of sample-performance is 73.3%. Kaggle Score: 0.72385 - this translates to an accuracy of 72.4%. As the top Kaggle score is around 0.8, there is obviously room for improvement, but the metrics are still fairly decent. That said, the recall and sensitivity is lower than we would like, indicating a need for further aggregation.

Because of the sheer amount of data, a good portion of it had to be sifted and filtered in order to find the most important factors. Even then, the graph of the first decision tree model was far too complex to interpret. Several factors were removed, as including them in prediction models could be considered discriminatory.

The top two predictors for the TARGET variable were EXT_SOURCE_3 and EXT_SOURCE_2 indicating that the scores HomeCredit received from external data sources were valuable information. The next group of predictors were related to occupation, which does make sense as we would expect to see a difference across occupations in lending. The group after this takes the client's credit history into account, examining the status of previous loans and late payments, which could also be natural predictors, and even red-flags for potential lenders. As much of this data came from files outside of the main data frames, it's clear that extending our analysis was worth the effort.

In retrospect, I would have used a different model type like a neural network or XGBoost for model building, or even a random forest to enhance recall. Additionally, I would use 10 fold cross validation to partition and train the data for better training. However, the model we ended up with is still something to be happy about. I bet HomeCredit would be happy with it too.
